import streamlit as st  
from langchain_prompts import ChatPromptTemplate  
from langchain_memory import ConversationBufferMemory  
from langchain_core import ConversationChain, RunnablePassthrough, StrOutputParser  
from langchain_openai import ChatOpenAI  


import os
from getpass import getpass
from langchain.memory import ConversationBufferMemory
from langchain.llms import OpenAI
from langchain.chains import ConversationChain

from langchain_core.runnables import RunnablePassthrough
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI


# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±  
prompt_template = ChatPromptTemplate.from_messages([  
    ("system",   
     "ì•ˆë…•í•˜ì„¸ìš”. ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”í•˜ê³  ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•´ ì£¼ì„¸ìš”. ğŸ˜Š"  
     "ì˜ ëª¨ë¥´ê² ëŠ” ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  'ëª¨ë¥´ê² ìŠµë‹ˆë‹¤' ë¦¬ê³  ëŒ€ë‹µí•´ ì£¼ì„¸ìš”."  
     "ë°ê³  ê¸ì •ì ì¸ íƒœë„ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”"),  
    ("human", "{input_text}")  
])  

memory = ConversationBufferMemory()  
conversation = ConversationChain(  
    llm=OpenAI(),  
    memory=memory,  
    verbose=False  
)  

# LangChain ì²´ì¸ ìƒì„±  
chain = {"input_text": RunnablePassthrough()} | prompt_template | OpenAI() | StrOutputParser()  

# Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜  
st.title("ëŒ€í™”í˜• AI ì±—ë´‡ ğŸ—¨ï¸")  
st.write("ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”í•´ìš”! ğŸ˜Š")  

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°  
user_input = st.text_input("ë‹¹ì‹ ì˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", "")  

# ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬  
if st.button("ì „ì†¡"):  
    if user_input:  
        # ì˜ˆì¸¡ í˜¸ì¶œ  
        response = conversation.predict(input=user_input)  
        st.text("AIì˜ ì‘ë‹µ: " + response)  
    else:  
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")  

st.sidebar.header("ì‚¬ìš©ë²•")  
st.sidebar.write("ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³  'ì „ì†¡' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")  
